Principles of political p2p economy

# **Principles of P2P-ness — Evaluation Framework**

This evaluation framework is extracted from the philosophical and theoretical approach described in the [p2p-nes assessment model tab](?tab=t.3iivis69qtmd). 

## **Introduction**

**Purpose:** To provide a structured framework for evaluating the degree of P2P-ness (peer-to-peer nature) of an organization or network. This helps with transparency, comparative study, identifying strengths/weaknesses, guiding improvement, and empirical observation.

**Scope:** Applies to organizations that self-identify (or might plausibly qualify) as P2P / Open Value Networks / commons / open networks, etc. The framework is intended for multi-scale evaluation — from individual projects, to open-enterprise structures, to networks of enterprises, up to inter-network or global collaborations.

**Theoretical Foundations:**

* Living systems theory: emergent structure, adaptation, interdependence among structure, process, culture.  
* Complexity economics: value is multi-dimensional; contributions are diverse; not all outcomes are predictable; feedback loops important.  
* OVN / Open Value Network model: open membership; transparency; contribution & value accounting; reputation; shared infrastructure; flexible roles; forking; governance at multiple levels.

## **Macro-Layers and Dimensions**

We divide evaluation into **four macro-layers**, each with multiple **dimensions**. For each dimension we give:

* Definition of the dimension  
* Why it matters for P2P-ness  
* Observable indicators or metrics  
* Sample scoring rubric

The four macro-layers are:

1. Structural/Formal  
2. Operational/Process  
3. Economic  
4. Cultural / Ecosystem / Superstructural

Also, evaluations should be done at multiple **Organizational Levels / Scales**:

* Project level  
* Open-Enterprise level (a self-contained organization)  
* Network level (multiple enterprises/projects)  
* Global / inter-network level

## **Dimensions, Indicators & Rubrics**

Below are the dimensions in each layer, with suggested indicators and how one might score them. Scores can be for example 0-4 or 0-5, where 0 \= “absent / not P2P at all on this dimension,” 5 \= “strongly present / meets P2P ideal well.”

### Structural / Formal Layer

| Dimension | Definition | Why It Matters | Indicators | Sample Rubric (0-5) |
| ----- | ----- | ----- | ----- | ----- |
| **Membership & Entry/Exit** | How open is membership; how easy is it to join, leave; is there gating or credentialing; different membership statuses; freedom to exit without harm. | A truly P2P organization generally allows wide participation, not restricted by elite or rare credentials; openness is part of peer equality. | \- Existence of formal membership criteria, and what they are. \- Whether membership is free, or cost/fee required. \- Types of membership status (observer, contributor, core). \- Exit / removal policies (are people locked in? can leave)? \- Transparency of membership records. | 0 \= closed/elite: only invitation; exit hard; opaque membership. 5 \= fully open: anybody can join or leave; very low barriers; recorded transparently. |
| **Role & Task Structure** | Formal roles (e.g. coordinators, maintainers, maintainers, core contributors), how tasks are allocated, role fluidity (changing, sharing, rotating). | If roles are rigid or hierarchical, P2P is weakened; fluidity allows peer leadership, adaptation, encourages diverse contribution. | \- Role definitions exist and are documented. \- Proportion of roles that are permanent vs temporary or emergent. \- Whether roles can be created/forked by peers. \- Whether tasks are self-assigned or centrally assigned. \- Role accountability / expectations well defined. | 0 \= very rigid hierarchy; fixed roles; tasks assigned from top; no ability for members to change role. 5 \= tasks fluid, roles emerge as needed; strong ability for any contributor to take or relinquish roles; task allocation via peer negotiation. |
| **Governance & Decision-Making** | How decisions are made: structures, formal mechanisms, how authority is distributed; multi-level governance. | Central to P2P: participatory, transparent, distributed decision making are key. | \- Existence of documented decision-making procedures. \- Whether decisions are consensus, voting, delegated, or hierarchical. \- Whether all members / contributors have voice in governance at different levels. \- Frequency of governance reviews or changes. \- Clarity and transparency of who decides what. | 0 \= decisions made by a few, opaque, centralized. 5 \= broad participation, decision rights distributed, transparent rules, multiple levels with appropriate local autonomy. |
| **Value Accounting & Rewards / Redistribution** | How contributions (of different types) are measured; how rewards, benefits, profits, recognition are distributed. | To ensure fairness; to avoid exploitation; to motivate; to align incentives across peers. | \- Existence of contribution logging, attribution systems. \- Types of contributions counted (e.g. code, writing, community work, admin). \- Whether reward / revenue / surplus is shared; how formula works. \- Whether non-financial rewards (reputation, recognition) are also formalized. \- Whether there is transparency in financials, surpluses, distributions. | 0 \= no value accounting; rewards go to a small elite; many contributions unrecognized. 5 \= rich accounting; rewards distributed fairly; non-financial contributions valued; full transparency. |
| **Legal / Financial Structure** | Legal entity forms, liability, ownership of assets, contracts; financial flow management. | Legal forms can enable or constrain openness; liability, risk, ownership affect trust and participation. | \- Whether there is a legal entity and what type (cooperative, nonprofit, benefit corporation, etc.) \- How contracts are held, who signs, who owns IP / commons infrastructure. \- How finances are handled. \- Risk / liability sharing. \- Funding sources (internal, external, membership, grants). | 0 \= closed legal forms where authority is centralized, liability uneven; finances opaque. 5 \= legal forms that reflect peer ownership / liability; clear contracts; finances transparent; shared risk. |
| **Infrastructure & Commons** | Shared tools, platforms, physical and digital commons; how ownership, maintenance, access work. | Commons are core to P2P; shared infrastructure reduces duplication, enables peer collaboration; but must be maintained and governed. | \- Existence of common platforms / tools; whether they are open source / open access. \- Who maintains infrastructure; whether maintenance burden is shared. \- Access rules: is commons accessible to all members / projects? \- Standards, interoperability, shared technical protocols. \- Funding / governance of commons maintenance. | 0 \= no shared infrastructure; tools proprietary or isolated; maintenance by few with little shared responsibility. 5 \= robust commons infrastructure; open; well maintained; shared ownership; accessible across projects. |

### Operational / Process Layer

| Dimension | Definition | Why It Matters | Indicators | Sample Rubric (0-5) |
| ----- | ----- | ----- | ----- | ----- |
| **Transparency & Access to Information** | Degree to which decisions, metrics, finances, plans, and process documentation are visible, accessible, and usable. | Without transparency, peer evaluation, trust, and accountability suffer; opaque organizations can claim P2P but act hierarchically. | \- Whether meeting minutes, decisions, roadmap, financials are published. \- Ease of access (public website, member portal). \- Regularity and timeliness of updates. \- Use of open licences / open access for documentation. \- Accessibility in terms of language, format, permissions. | 0 \= most processes hidden; only insiders see; ad hoc documentation. 5 \= full transparency; documents published promptly; accessible to all; tools permit easy discovery. |
| **Coordination of Tasks & Workflows** | How work is organized, dependencies handled, peer coordination, self-organization, distribution of workload. | P2P works well when people coordinate without rigid hierarchy; dependencies managed, duplication minimized; people free to contribute where they want. | \- Tools/processes for coordination (issue trackers, kanban boards, shared calendars) \- Degree of self-assignment of work vs assignment by others \- Mechanisms for managing dependencies between tasks/projects \- Regular syncs / coordination meetings etc \- Ability of projects to fork / spin-off if needed. | 0 \= centralized assignment; heavy bottlenecks; poor coordination; many blocked tasks. 5 \= self-assignment common; workflows visible; good coordination; minimal bottlenecks; forks allowed. |
| **Contribution Logging & Attribution** | The degree to which contribution of peers is recorded, credited, and visible. | Attribution builds trust, encourages participation, helps with reward / reputation systems. Without it, contributions may be invisible or unfairly taken. | \- Is there a contribution tracking system? \- How granular is it (small contributions vs just big ones)? \- Is attribution used in reward / reputation? \- Is historical contribution preserved across changes / forks / reorganizations? \- Are non-technical / less visible contributions recognized? | 0 \= little or no attribution; mostly informal or verbal recognition; many invisible contributions. 5 \= detailed, persistent record; wide types of contributions; used in reputation / reward; non-technical contributions visible. |
| **Conflict Management & Forking** | How disagreements are handled; whether forking (projects splitting) is allowed; mechanisms for mediation, resolution. | Conflict is inevitable; P2P requires safe, fair, and accessible paths for resolving conflict; forking is a safety valve to avoid stagnation or authoritarian drift. | \- Existence of documented conflict resolution policies. \- Existence of mediation / arbitration mechanisms. \- Whether forking is allowed (technical / organizational). \- Whether forking processes preserve or migrate value/contributions. \- How conflicts have been handled in practice historically. | 0 \= no clear policy; conflicts suppressed; no capacity to fork; centralized authority overrides. 5 \= robust policies; forking allowed and supported; conflict resolution accessible; precedents followed. |
| **Reputation, Trust & Accountability** | Systems or norms for trusting peers; reputation mechanisms; how accountability is enforced or encouraged. | In peer systems, formal power is weaker; trust and reputation are often what ensure reliability and cooperation. Accountability ensures reliability and reduces free-rider problems. | \- Existence of reputation systems (rating, peer review, reputational badges, etc.). \- Norms/expectations of reliability. \- Visibility of past performance. \- Mechanisms for feedback and review. \- Consequences for failing to meet commitments. | 0 \= reputation minimal / no feedback; trust weak; broken promises tolerated without consequence. 5 \= strong reputation system; feedback loops; peer review; non-compliance documented and addressed. |

### Economic Layer

| Dimension | Definition | Why It Matters | Indicators | Sample Rubric (0-5) |
| ----- | ----- | ----- | ----- | ----- |
| **Property Regime & Licensing (Commons/Nondominium vs Proprietary)** | How outputs and infrastructure are owned/licensed (e.g., open licenses, nondominium, trademark posture). | P2P rests on a commons logic; restrictive IP undermines peer access, forkability, and long-term commons stewardship. | \- LICENSE files (OSI/CC) and CLAs. \- Trademark/brand policies for forks/naming. \- Nondominium/commons stewards identified. | 0 \= proprietary/assignment to central org; 5 \= permissive/open licensing; trademarks allow fair forks; nondominium stewards present. |
| **Contribution Accounting / Benefit Distribution** | How diverse contributions are logged and how benefits/surplus are distributed. | Ensures fairness, recognizes non-code labor, and aligns incentives for sustained participation. | \- Contribution logs across roles (code \+ non-code). \- Transparent value equations/reward rules. \- Public distributions/retro funding records. | 0 \= opaque/no attribution; 5 \= multi-dimensional accounting; transparent, proportional distributions. |
| **Funding & Capital Sources** | Mix of grants, donations, service revenue, subscriptions, token issuance/investment. | Funding mix shapes power and capture risks; diversified, commons-aligned funding improves resilience. | \- Grants/partner revenue share. \- Investor/token allocations. \- Donor concentration indices. | 0 \= highly concentrated, investor-driven; 5 \= diversified, community-aligned funding with low capture risk. |
| **Revenue Model & Market Interface** | How sustainability is achieved (services around commons, open-core, subscriptions, marketplaces). | Models can reinforce commons (services) or re-centralize power (closed tiers); affects openness and incentives. | \- Presence of open-core/dual licensing. \- Service/hosting offerings around open core. \- Cost transparency (where applicable). | 0 \= closed monetization capturing commons; 5 \= services that strengthen commons; transparent cost basis. |
| **Tokenomics & Incentives (if applicable)** | Token distribution, vesting, voting power, incentive alignment with participation. | Poor token design centralizes power; good design rewards contribution and broad participation. | \- Token distribution charts, vesting, top holder concentration. \- Governance power mapping. | 0 \= insider-heavy, non-participatory; 5 \= widely distributed, contribution-aligned, low capture risk. |
| **Cost Structure & Sustainability** | Opex/infra costs, runways, ecological/resource costs transparency. | Economic durability without compromising commons; visibility of externalities/ecology. | \- Infra cost disclosures; budgets. \- Eco-impact transparency (energy, hosting, travel). | 0 \= opaque costs/externalities; 5 \= transparent costs, sustainable plan, eco-accounting. |
| **Economic Openness & Cost Transparency** | Visibility of costs, budgets, grant criteria, and allocation rules (recognizing non-transactional dissemination). | Transparency enables peer verification and reduces rent-seeking. | \- Public budgets and cost breakdowns. \- Clear criteria for allocations. | 0 \= opaque; 5 \= consistently published, auditable economic data. |

### Cultural / Ecosystem / Superstructural Layer

| Dimension | Definition | Why It Matters | Indicators | Sample Rubric (0-5) |
| ----- | ----- | ----- | ----- | ----- |
| **Values, Norms & Culture** | What values are declared & practiced; how norms shape behaviour; whether there is alignment between what is said and what is done. | Culture underpins how all other layers function; strong P2P culture supports trust, openness, fairness; misalignment undermines legitimacy. | \- Existence of declared values / code of ethics / manifesto. \- Whether behaviors align (e.g. leaders follow norms). \- Whether newcomers are socialized into norms. \- How violations of norms are handled. \- Feedback from members about culture, inclusion, power. | 0 \= values vague or missing; culture contradictory; values ignored; norm violations common and unaddressed. 5 \= values clear & lived; high alignment; norms upheld; culture perceived as inclusive; members feel safe. |
| **Learning, Adaptation & Innovation** | How the organization learns from experience; how it adapts to internal or external changes; how experimentation is supported. | Systems that can’t adapt stagnate; P2P organizations are especially challenged with complexity and change, so adaptability is critical. | \- Whether periodic reviews or retrospectives take place. \- How feedback is collected (from members, users, external). \- Whether experiments / innovation are encouraged or penalized. \- How quickly change is implemented when needed. \- Whether failures are acknowledged and lessons shared. | 0 \= rigid, slow to change; feedback ignored; mistakes repeated. 5 \= frequent review; experiment culture; lessons institutionalized; responsive adaptation. |
| **Meaning, Purpose & Identity** | Shared mission, vision; sense of belonging; narratives of P2P; identity across levels. | Strong shared purpose aligns incentives, motivates members, helps resolve conflicts. Identity helps cohesion and resilience. | \- Presence of clear mission / vision statements. \- Member interviews / surveys about alignment with mission. \- Narrative / storytelling practices (blogs, talks, branding). \- Identity across projects vs “enterprise” vs network. \- Whether identity is inclusive / adaptive. | 0 \= mission vague or only on paper; members don’t feel connected; identity fragmented. 5 \= mission internalized; strong belonging; identity coherent; identity helps joiners integrate quickly. |
| **External Ecosystem & Relations** | How the organization interacts with external actors: other networks, communities; openness to collaboration; impact; relations to broader commons. | P2P doesn’t exist in isolation; networks, supply / value chains, commons; being embedded in ecosystem enhances resilience, scope, legitimacy. | \- Number & quality of external partnerships / collaborations. \- Whether external contributions are accepted / external actors allowed in. \- Whether learnings / tools / outputs are shared externally (open licence etc). \- Whether the organization contributes back to wider commons. \- Whether ecosystem dependence (supply chains, etc.) is transparent. | 0 \= isolated, closed; no external sharing; collaborations minimal or extractive. 5 \= highly embedded; open to external engagement; outputs shared; ecosystem relationships reciprocal. |

## **Levels of Scale**

For each of the above dimensions, it’s important to assess at **each level**:

* **Project Level:** small units / teams / individual endeavors.  
* **Open-Enterprise Level:** the overarching organization that holds legal, financial, HR, infrastructure functions.  
* **Network Level:** connections among enterprises/projects, federations, alliances.  
* **Global / Inter-Network Level:** relationships beyond direct network; standards, norms, global influence, global commons.

Some dimensions will manifest differently at each level. For example:

* Decision-making might be very participatory at project level, but more constrained at enterprise level due to legal or financial imperatives.  
* Commons infrastructure might exist at enterprise level (tools for internal use) and network level (shared platforms), but less so at global level.

Thus, for a complete evaluation, one fills out the dimension score for each level, or at least for the levels relevant to the organization.

## **Rubric / Scoring & Aggregation**

A suggestion for how to turn per-dimension & per-level evaluations into an overall “P2P-ness” profile / score:

* Each dimension (at each level) gets a score 0-4 or 0-5.  
* You may weight dimensions differently depending on context (e.g. a small community project may emphasize culture and contribution more than legal structure).  
* You can compute:

  * **Layer scores** \= average over dimensions in that layer (across levels),  
  * **Level scores** \= average over dimensions across layers for that level,  
  * **Overall P2P-ness score** \= weighted average of layer and/or level scores.

* In addition to numeric scores, also note **qualitative observations**: what is working well, what is being blocked, what trade-offs are evident.  
* It may be useful to produce a radar/spider diagram showing scores across dimensions and levels — for visualization and comparative purposes.

## **Interdependencies, Trade-Offs, Tensions**

No organization is perfect in all dimensions. Possible trade-offs:

* Openness / transparency vs privacy / security.  
* Fluid roles vs stability / consistency.  
* Decision speed vs inclusiveness.  
* Value distribution fairness vs incentives to attract external funding or investment.  
* Protocols / standards (which help coordination) vs freedom / flexibility.

In evaluation, document where tensions exist, how the organization addresses them, and whether the solution leans toward more or less P2P-ness in particular dimensions.

## **Data Sources & Observation Methods**

To do empirical evaluation, one can gather data from:

* Documents: constitutions, bylaws, governance manuals, membership criteria.  
* Publicly published records: meeting minutes, financial reports, decisions, roadmaps.  
* Tools / platforms in use: issue trackers, code bases, collaboration platforms.  
* Observations / ethnography: how meetings work, how decisions are made in practice, who shows up, who speaks up.  
* Surveys / interviews of members, contributors: perceptions of fairness, identity, trust.  
* Contribution logs: version control, timestamps, commit attribution, tags, etc.  
* Conflict / fork histories: if projects have forked, how that went.  
* External collaboration records: partnerships, sharing, open licensing.

## **Sample Case Application (Hypothetical)**

To illustrate, one might evaluate an organization X. Fill in a table:

| Level / Layer | Dimension | Score (0-5) | Rationale / Evidence |
| ----- | ----- | ----- | ----- |
| Project level / Transparency | Transparency & Access | 4 | Minutes are published, roadmap available; some delays in updates. |
| Enterprise level / Governance | Governance & Decision-Making | 2 | Formal governance exists but many decisions are centralized in the core team. |
| Network level / Commons | Infrastructure & Commons | 5 | Shared platform across all projects; open source; maintenance distributed. |
| ... | ... | ... | ... |

Then compute layer & level averages, note qualitative strengths and areas for improvement.

## **Example Rubric Summary Table**

Here’s a condensed rubric you might include in the document as a summary:

| Score | What it means generally |
| ----- | ----- |
| **0** | No evidence / opposite of P2P principle; dimension largely absent or highly centralized   |
| **1** | Minimal presence; some token or partial features but weak or inconsistent |
| **2** | Some features present; but significant gaps; not reliably practiced |
| **3** | Moderate presence; many features are present and function in practice, though not perfect |
| **4** | Strong presence; most features present and practiced; high fidelity to P2P ideals |
| **5** | Exemplary; dimension is implemented robustly; model / practice could be a benchmark for others |

## **Concluding Recommendations & Pathways of Improvement**

After evaluation, the document should include guidance / strategies for organizations to improve their P2P-ness, for example:

* For dimensions with low scores, identify specific interventions: e.g. improve transparency by instituting regular public publications; improve membership openness by reducing fees or credential requirements; develop reputation systems.  
* Identify “quick wins” vs long-term changes.  
* Encourage piloting changes at the project level (easier, lower stakes), then scale up.  
* Document trade-offs and choose consciously how to balance them rather than letting implicit defaults drive structure.  
